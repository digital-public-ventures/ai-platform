WEBUI_NAME="DPV AI Platform"
# Ollama URL for the backend to connect
# The path '/ollama' will be redirected to the specified backend URL
OLLAMA_BASE_URL='http://localhost:11434'

# For production, you should only need one host as
# fastapi serves the svelte-kit built frontend and backend from the same host and port.
# To test with CORS locally, you can set something like
# CORS_ALLOW_ORIGIN='http://localhost:5173;http://localhost:8080'
CORS_ALLOW_ORIGIN='*'

# For production you should set this to match the proxy configuration (127.0.0.1)
FORWARDED_ALLOW_IPS='*'

# Environment
ENVIRONMENT=development
WEBUI_SECRET_KEY="not a secret on local deploy"
SHOW_ONBOARDING=false

# DO NOT TRACK
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false
# HF_HUB_OFFLINE=1

OPENAI_API_KEY=
OPENAI_API_BASE_URL='https://api.openai.com/v1'

# RAG_EMBEDDING_ENGINE=openai
# RAG_EMBEDDING_MODEL=text-embedding-3-small
# RAG_OPENAI_API_KEY=
# RAG_OPENAI_API_BASE_URL='https://api.openai.com/v1'

# WebSocket Configuration
# ENABLE_WEBSOCKET_SUPPORT=true
# WEBSOCKET_REDIS_URL="redis://:@localhost:6381"
# REDIS_URL="redis://localhost:6381"
# WEBSOCKET_MANAGER=redis

# DB Connection
# DATABASE_URL="postgres://postgres:postgres@localhost:5434/postgres"
# VECTOR_DB=pgvector

# Use these if running a separate open webui pipelines server
# OPENAI_API_KEY=0p3n-w3bu!
# OPENAI_API_BASE_URL=http://localhost:9099
